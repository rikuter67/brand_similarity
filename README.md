ファッションブランドライン類似度分析のためのスタイル情報拡張プロジェクト1. プロジェクト概要本プロジェクトは、ファッションブランドの各ラインに関する説明文（description）に対し、大規模言語モデル（LLM）を用いてファッションスタイルに関する情報（キースタイル/コンセプト、代表的なアイテム、素材や色使いの特徴、ターゲット顧客層のイメージなど）を補完・生成することを目的としています。既存の説明文はブランドの歴史や沿革が中心であることが多く、またHTMLタグが混入していたり、情報が冗長であったりする場合があります。本プロジェクトでは、これらの説明文をクリーニングし、LLMを活用してスタイル情報を付加することで、よりファッション的な観点からブランドライン間の類似度を分析するための質の高いテキストデータを生成します。最終的には、生成された充実した説明文をベクトル化し、ブランドライン間の類似度計算、クラスタリング、可視化など、さらなる分析へ繋げることを目指します。これは、過去に実施された「共通施設数」に基づく物理的な近さの分析を補完し、より多角的で深い洞察を得るための取り組みです。2. 使用データblines.csv: 主要な入力データ。ブランドラインのID、名称 (name カラム)、既存の説明文 (description カラム) などが含まれます。brands.csv: ブランドID、ブランド名、ブランドカテゴリなどの情報が含まれます。（本スクリプトでは直接使用していませんが、blines.csv に事前にブランド情報がマージされていることを想定しています。もしマージされていない場合は、適宜スクリプトのデータ読み込み部分で対応が必要です。）データは /datasets/bline_similarity/ ディレクトリに配置することを想定しています。3. 主要な処理フローデータ読み込みと前処理:blines.csv を読み込みます。description カラムに含まれるHTMLタグを除去し、不要な改行や空白を整理して description_cleaned カラムを作成します。LLMによるスタイル情報特化型ディスクリプション生成:ローカルに配置された日本語LLM（例: ELYZA-japanese-Llama-2-7b）を使用します。few_shot.py ファイルに定義されたFew-shotの例とプロンプトテンプレートを活用します。既存説明文の長さに応じた条件分岐処理:長文の場合 (desc_len_chars > presummary_threshold):まず、LLMに長文の既存説明文からファッションスタイルに関連する情報を中心に400字程度で事前要約させます。その要約結果を「既存の説明文」として、スタイル情報の要約・再構成を促すプロンプト（PROMPT_TEMPLATE_SUMMARIZE_RESTRUCTURE）を適用します。中程度の文の場合 (desc_len_chars > generate_complement_threshold):スタイル情報の補完・生成を促すプロンプト（PROMPT_TEMPLATE_GENERATE_COMPLEMENT）を適用します。短文またはほぼ情報がない場合:ブランドライン名のみを主な手がかりとしてスタイル情報を完全新規生成させるプロンプト（PROMPT_TEMPLATE_GENERATE_NEW）を適用します。生成されたスタイル情報を含む新しい説明文は description_styled カラムに格納されます。結果の保存:処理後のデータフレーム（description_styled カラムを含む）を、タイムスタンプ付きの新しいCSVファイルとして /datasets/bline_similarity/ ディレクトリに保存します。（例: blines_with_AI_styled_descriptions_YYYYMMDDHHMM.csv）各ブランドラインの生成処理に関するログ（使用したプロンプトタイプ、生成結果など）も別途CSVファイルとして保存されます。4. 必要なライブラリ・環境Python 3.xpandastransformers (pip install transformers)torch (pip install torch torchvision torchaudio - ご自身の環境に合わせてCUDA版も検討してください)tqdm (pip install tqdm)BeautifulSoup4 (pip install beautifulsoup4)accelerate (pip install accelerate - device_map="auto" を使用する場合に推奨)LLMモデルファイル: ELYZA-japanese-Llama-2-7b などの日本語LLMモデルファイル一式。スクリプト内の model_path で指定されたディレクトリ（例: /mnt/c/Users/rikuter/Carlin/model/）に配置してください。5. ファイル構成（推奨）.
├── generate_styled_descriptions.py  # このメイン処理スクリプト
├── few_shot.py                      # Few-shotの例とプロンプトテンプレートを定義
├── datasets/
│   └── bline_similarity/
│       ├── blines.csv               # 入力するブランドラインデータ
│       ├── brands.csv               # (任意) ブランド情報データ
│       └── (ここに生成されたCSVファイルが出力されます)
├── model/                           # LLMモデルファイル一式を格納
│   └── (ELYZA-japanese-Llama-2-7b など)
└── README.md                        # このファイル
6. 実行方法以下のコマンドライン引数を使用してスクリプトを実行します。python generate_styled_descriptions.py [オプション]
主要なオプション:--mode TEXT: 実行モードを選択 (validation または production)。validation: 少数のサンプルでテスト実行（デフォルト）。production: 全データで実行。--num_samples INTEGER: 検証モードで処理するサンプル数（デフォルト: 3）。--max_tokens INTEGER: LLMがスタイル説明文を生成する際の最大トークン数（デフォルト: 500）。--max_summary_tokens INTEGER: LLMが事前要約を生成する際の最大トークン数（デフォルト: 150）。--temperature FLOAT: LLM生成時のtemperature（デフォルト: 0.75）。値が低いほど決定的、高いほど多様な出力になります。`--presummary_threshold INTEGER